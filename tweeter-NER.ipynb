{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP-Empowered-Named-Entity-Recognition\n",
    "    EntitySense utilizes advanced NLP techniques to automatically identify and categorize entities in text data. With deep learning and semantic analysis, it offers accurate entity recognition, enabling applications like information extraction and sentiment analysis across different domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Twitter is a microblogging and social networking service on which users post and interact with messages known as \"tweets\". Every second, on average, around 6,000 tweets are tweeted on Twitter, corresponding to over 350,000 tweets sent per minute, 500 million tweets per day.\n",
    "\n",
    "Twitter wants to automatically tag and analyze tweets for better understanding of the trends and topics without being dependent on the hashtags that the users use. Many users do not use hashtags or sometimes use wrong or mis-spelled tags, so they want to completely remove this problem and create a system of recognizing important content of the tweets.\n",
    "\n",
    "Named Entity Recognition (NER) is an important subtask of information extraction that seeks to locate and recognise named entities.\n",
    "\n",
    "You need to train models that will be able to identify the various named entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Dataset is annotated with 10 fine-grained NER categories: person, geo-location, company, facility, product,music artist, movie, sports team, tv show and other. Dataset was extracted from tweets and is structured in CoNLL format., in English language. Containing in Text file format.\n",
    "\n",
    "The CoNLL format is a text file with one word per line with sentences separated by an empty line. The first word in a line should be the word and the last word should be the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        # Read the lines of the file\n",
    "        lines = file.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SammieLynnsMom\tO\n",
      " @tg10781\tO\n",
      " they\tO\n",
      " will\tO\n",
      " be\tO\n",
      " all\tO\n",
      " done\tO\n",
      " by\tO\n",
      " Sunday\tO\n",
      " trust\tO\n",
      " \n",
      "Total number of lines: 48862\n"
     ]
    }
   ],
   "source": [
    "filename = \"Datasets/wnut 16.txt.conll\"\n",
    "lines = read_file(filename)\n",
    "for i in range(10):\n",
    "    print(lines[i], end=\" \")\n",
    "\n",
    "print(\"\\nTotal number of lines:\", len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New\tB-other\n",
      " Orleans\tI-other\n",
      " Mother\tI-other\n",
      " 's\tI-other\n",
      " Day\tI-other\n",
      " Parade\tI-other\n",
      " shooting\tO\n",
      " .\tO\n",
      " One\tO\n",
      " of\tO\n",
      " \n",
      "Total number of lines: 65757\n"
     ]
    }
   ],
   "source": [
    "filename = \"Datasets/wnut 16test.txt.conll\"\n",
    "lines = read_file(filename)\n",
    "for i in range(10):\n",
    "    print(lines[i], end=\" \")\n",
    "\n",
    "print(\"\\nTotal number of lines:\", len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    # Define column names based on the CoNLL format\n",
    "    column_names = [\"Word\", \"NER\"]\n",
    "\n",
    "    # Read the data from the file\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Initialize an empty list to store formatted data\n",
    "    formatted_data = []\n",
    "\n",
    "    # Parse each line and append to formatted_data\n",
    "    for line in lines:\n",
    "        # Remove leading/trailing whitespaces and split by tabs\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        # Ignore empty lines\n",
    "        \n",
    "        formatted_data.append(parts)\n",
    "\n",
    "    # Convert the list of lists into a DataFrame\n",
    "    df = pd.DataFrame(formatted_data, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_file(\"Datasets/wnut 16.txt.conll\")\n",
    "df_test = read_file(\"Datasets/wnut 16test.txt.conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@SammieLynnsMom</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@tg10781</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word NER\n",
       "0  @SammieLynnsMom   O\n",
       "1         @tg10781   O\n",
       "2             they   O\n",
       "3             will   O\n",
       "4               be   O"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New</td>\n",
       "      <td>B-other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Orleans</td>\n",
       "      <td>I-other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mother</td>\n",
       "      <td>I-other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'s</td>\n",
       "      <td>I-other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day</td>\n",
       "      <td>I-other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word      NER\n",
       "0      New  B-other\n",
       "1  Orleans  I-other\n",
       "2   Mother  I-other\n",
       "3       's  I-other\n",
       "4      Day  I-other"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data shape: (48862, 2)\n",
      "\n",
      "Data shape: (65757, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData shape:\", df_train.shape)\n",
    "print(\"\\nData shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "--------------------\n",
      "Word       0\n",
      "NER     2393\n",
      "dtype: int64\n",
      "--------------------\n",
      "Word       0\n",
      "NER     3849\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values:\")\n",
    "print(\"-\"*20)\n",
    "print(df_train.isnull().sum())\n",
    "print(\"-\"*20)\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "--------------------\n",
      "Word    0\n",
      "NER     0\n",
      "dtype: int64\n",
      "--------------------\n",
      "Word    0\n",
      "NER     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values:\")\n",
    "print(\"-\"*20)\n",
    "print(df_train.isnull().sum())\n",
    "print(\"-\"*20)\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded labels: [0 1 1 1 1]\n",
      "Tokenized inputs: {'input_ids': tensor([[ 101, 2047,  102,    0],\n",
      "        [ 101, 5979,  102,    0],\n",
      "        [ 101, 2388,  102,    0],\n",
      "        [ 101, 1005, 1055,  102],\n",
      "        [ 101, 2154,  102,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 0],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 1, 0],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 0]])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Your dataset\n",
    "data = {\n",
    "    \"Word\": [\"New\", \"Orleans\", \"Mother\", \"'s\", \"Day\"],\n",
    "    \"NER\": [\"B-other\", \"I-other\", \"I-other\", \"I-other\", \"I-other\"]\n",
    "}\n",
    "\n",
    "# Encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"NER_encoded\"] = label_encoder.fit_transform(data[\"NER\"])\n",
    "\n",
    "# Prepare inputs for the model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "inputs = tokenizer(data[\"Word\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(\"Encoded labels:\", data[\"NER_encoded\"])\n",
    "print(\"Tokenized inputs:\", inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>NER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13924</th>\n",
       "      <td>before</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13542</th>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28890</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45037</th>\n",
       "      <td>following</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15133</th>\n",
       "      <td>not</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20980</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20799</th>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64137</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64742</th>\n",
       "      <td>French</td>\n",
       "      <td>B-company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>https://t.co/MwgDe5UB08</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51759</th>\n",
       "      <td>European</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48603</th>\n",
       "      <td>there</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27530</th>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>B-product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60466</th>\n",
       "      <td>http://t.co/HxNle4zGkW</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59319</th>\n",
       "      <td>@ZDnet</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64036</th>\n",
       "      <td>Broadcast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8486</th>\n",
       "      <td>new</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32353</th>\n",
       "      <td>eBay</td>\n",
       "      <td>B-company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>When</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33456</th>\n",
       "      <td>@kirbydickens</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Word        NER\n",
       "13924                   before          O\n",
       "13542                        :          O\n",
       "28890                       in          O\n",
       "45037                following          O\n",
       "15133                      not          O\n",
       "20980                        ,          O\n",
       "20799                        ?          O\n",
       "64137                       to          O\n",
       "64742                   French  B-company\n",
       "7323   https://t.co/MwgDe5UB08          O\n",
       "51759                 European          O\n",
       "48603                    there          O\n",
       "27530                Chevrolet  B-product\n",
       "60466   http://t.co/HxNle4zGkW          O\n",
       "59319                   @ZDnet          O\n",
       "64036                Broadcast          O\n",
       "8486                       new          O\n",
       "32353                     eBay  B-company\n",
       "5425                      When          O\n",
       "33456            @kirbydickens          O"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
